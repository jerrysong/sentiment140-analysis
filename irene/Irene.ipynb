{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jooyeon_seo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, CuDNNLSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keeping the necessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/sentiment140_train.zip', encoding='ISO-8859-1', header=None, names=['sentiment','id','timestamp','type','user','text'])\n",
    "test_data = pd.read_csv('../data/sentiment140_test.zip', encoding='ISO-8859-1', header=None, names=['sentiment','id','timestamp','type','user','text'])\n",
    "\n",
    "# The original training data are sorted by sentiment value. Shuffle the training data for randomness\n",
    "train_data = train_data[['text','sentiment']].sample(frac=1)\n",
    "test_data = test_data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         object\n",
       "sentiment     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1362915</th>\n",
       "      <td>please this account is inactive i would like t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405689</th>\n",
       "      <td>I do miss her! at t'time u didn't catch my jok...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349269</th>\n",
       "      <td>friday already??? rajskub, you are right, life...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101823</th>\n",
       "      <td>No! Please don't rain! Sunshine I already miss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228317</th>\n",
       "      <td>@popstarmagazine http://twitpic.com/6djtf - @s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273018</th>\n",
       "      <td>Just finished late night with @jimmyfallon... ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634879</th>\n",
       "      <td>@jojo_the_brat sorry, my phone is being SUPER ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487446</th>\n",
       "      <td>i was too late to the zoo and didnt get to see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556869</th>\n",
       "      <td>@judithkeane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195237</th>\n",
       "      <td>Good night twitter ;).  Aww... My baby is sick...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  sentiment\n",
       "1362915  please this account is inactive i would like t...          4\n",
       "1405689  I do miss her! at t'time u didn't catch my jok...          4\n",
       "1349269  friday already??? rajskub, you are right, life...          4\n",
       "101823   No! Please don't rain! Sunshine I already miss...          0\n",
       "1228317  @popstarmagazine http://twitpic.com/6djtf - @s...          4\n",
       "1273018  Just finished late night with @jimmyfallon... ...          4\n",
       "634879   @jojo_the_brat sorry, my phone is being SUPER ...          0\n",
       "487446   i was too late to the zoo and didnt get to see...          0\n",
       "556869                                       @judithkeane           0\n",
       "195237   Good night twitter ;).  Aww... My baby is sick...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fuck this economy. I hate aig and their non lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jquery is my new best friend.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Loves twitter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how can you not love Obama? he makes jokes abo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...          4\n",
       "1  Reading my kindle2...  Love it... Lee childs i...          4\n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...          4\n",
       "3  @kenburbary You'll love your Kindle2. I've had...          4\n",
       "4  @mikefish  Fair enough. But i have the Kindle2...          4\n",
       "5  @richardebaker no. it is too big. I'm quite ha...          4\n",
       "6  Fuck this economy. I hate aig and their non lo...          0\n",
       "7                      Jquery is my new best friend.          4\n",
       "8                                      Loves twitter          4\n",
       "9  how can you not love Obama? he makes jokes abo...          4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rows: 800000\n",
      "Negative rows: 800000\n"
     ]
    }
   ],
   "source": [
    "print('Positive rows: {}'.format(train_data[ train_data['sentiment'] == 4]['sentiment'].size))\n",
    "print('Negative rows: {}'.format(train_data[ train_data['sentiment'] == 0]['sentiment'].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Baseline NB model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000,) (800000,)\n",
      "(800000,) (800000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = train_data['text'].values[len(train_data['sentiment'])//2:], train_data['sentiment'].values[len(train_data['sentiment'])//2:]\n",
    "X_dev, Y_dev = train_data['text'].values[:len(train_data['sentiment'])//2], train_data['sentiment'].values[:len(train_data['sentiment'])//2]\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_dev.shape, Y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive train data:  400295 , negative train data:  399705\n",
      "positive dev data:  399705 , negative dev data:  400295\n"
     ]
    }
   ],
   "source": [
    "print ('positive train data: ', len(np.where(Y_train==4)[0]), \n",
    "       ', negative train data: ', len(np.where(Y_train==0)[0]))\n",
    "print ('positive dev data: ', len(np.where(Y_dev==4)[0]), \n",
    "       ', negative dev data: ', len(np.where(Y_dev==0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary is 10000\n",
      "(800000, 10000) (800000,)\n"
     ]
    }
   ],
   "source": [
    "# transform text data using Tfidf vectorizer\n",
    "max_features = 10000\n",
    "tfidf = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), min_df=2, \n",
    "                        stop_words='english', use_idf=False, sublinear_tf=True, max_features=max_features)\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_dev = tfidf.transform(X_dev)\n",
    "train_tfidf_names = tfidf.get_feature_names()\n",
    "print(\"Size of the vocabulary is\", tfidf_train.shape[1])\n",
    "print(tfidf_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 0-weight terms using logistic regression\n",
    "logreg = LogisticRegression(penalty='l1', tol=0.01, C=10)\n",
    "logreg.fit(tfidf_train, Y_train)\n",
    "nonzero_feature_index = np.array(np.nonzero(logreg.coef_[0])[0])\n",
    "features = [train_tfidf_names[int(w)] for w in nonzero_feature_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary is 9634\n",
      "(800000, 9634) (800000,)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(use_idf=False, sublinear_tf=True, vocabulary=list(set(features)))\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_dev = tfidf.transform(X_dev)\n",
    "print(\"Size of the vocabulary is\", tfidf_train.shape[1])\n",
    "print(tfidf_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.77      0.76    393498\n",
      "          4       0.77      0.76      0.76    406502\n",
      "\n",
      "avg / total       0.76      0.76      0.76    800000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB(alpha=0.01)\n",
    "bnb.fit(tfidf_train, Y_train)\n",
    "predicted = bnb.predict(tfidf_dev)\n",
    "print (classification_report(predicted, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 9634)\n",
      "[[ -7.47790286 -10.18976546  -9.85348359 ...  -9.20935268 -10.18976546\n",
      "   -6.17463764]\n",
      " [ -7.01105145  -9.49842644  -9.64147602 ...  -8.60936069  -9.7640282\n",
      "   -6.39565396]]\n"
     ]
    }
   ],
   "source": [
    "log_prob = bnb.feature_log_prob_\n",
    "print(log_prob.shape)\n",
    "print(log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.65441985e-04, 3.75526932e-05, 5.25637631e-05, ...,\n",
       "        1.00098818e-04, 3.75526932e-05, 2.08156005e-03],\n",
       "       [9.01859833e-04, 7.49697061e-05, 6.49770762e-05, ...,\n",
       "        1.82390478e-04, 5.74826037e-05, 1.66879418e-03]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = np.exp(log_prob)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.50184499e-08 2.50184499e-08 2.50184499e-08 ... 4.91887993e-02\n",
      "  5.48479726e-02 7.78099059e-02]\n",
      " [2.49815748e-08 2.49815748e-08 2.49815748e-08 ... 5.78823339e-02\n",
      "  7.42802396e-02 7.64311532e-02]]\n"
     ]
    }
   ],
   "source": [
    "sorted_prob = np.copy(prob)\n",
    "sorted_prob.sort(axis=1)\n",
    "print(sorted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive words: ['today', 'day', 'love', 'http', 'like', 'lol', 'good', 'com', 'thanks', 'going']\n",
      "Top 10 negative words: ['really', 'today', 'day', 'don', 'like', 'work', 'miss', 'got', 'going', 'want']\n"
     ]
    }
   ],
   "source": [
    "log_prob = bnb.feature_log_prob_\n",
    "prob = np.exp(log_prob)\n",
    "sorted_prob = np.copy(prob)\n",
    "sorted_prob.sort(axis=1)\n",
    "feature_names = tfidf.get_feature_names()\n",
    "# Save 20 features in a list\n",
    "positive_index = []\n",
    "negative_index = []\n",
    "positive_feature_list = []\n",
    "negative_feature_list = []\n",
    "for i in range(len(prob[1])):\n",
    "    if prob[1][i] in sorted_prob[1][-11:-1]:\n",
    "        positive_index.append(i)\n",
    "for ind in positive_index:\n",
    "    positive_feature_list.append(feature_names[ind])\n",
    "    \n",
    "for i in range(len(prob[0])):\n",
    "    if prob[0][i] in sorted_prob[0][-11:-1]:\n",
    "        negative_index.append(i)\n",
    "for ind in negative_index:\n",
    "    negative_feature_list.append(feature_names[ind])\n",
    "    \n",
    "print(\"Top 10 positive words:\", positive_feature_list)\n",
    "print(\"Top 10 negative words:\", negative_feature_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
