{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "6c53202d-5c34-4859-e7e9-8ef5c7068287"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, CuDNNLSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bc2702e-d6f4-df5f-b80e-50ab23a6d29e"
   },
   "source": [
    "Only keeping the necessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "89c8c923-c0bf-7b35-9ab8-e63f00b74e5a"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/sentiment140_train.zip', encoding='ISO-8859-1', header=None, names=['sentiment','id','timestamp','type','user','text'])\n",
    "test_data = pd.read_csv('../data/sentiment140_test.zip', encoding='ISO-8859-1', header=None, names=['sentiment','id','timestamp','type','user','text'])\n",
    "\n",
    "# The original training data are sorted by sentiment value. Shuffle the training data for randomness\n",
    "train_data = train_data[['text','sentiment']].sample(frac=1)\n",
    "test_data = test_data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         object\n",
       "sentiment     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1191014</th>\n",
       "      <td>@empian sure is, and they were on offer so tas...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458592</th>\n",
       "      <td>............      orlando magic making me sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086868</th>\n",
       "      <td>@iAmCherAnn Really? Allison said that?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387691</th>\n",
       "      <td>i want to go to america NOW! i dont want to wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552737</th>\n",
       "      <td>Dont like going to sleep after being full off ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521780</th>\n",
       "      <td>@kaypros Thanks. You are so right - great venu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140025</th>\n",
       "      <td>Kobayashi beats Chestnut! http://tinyurl.com/n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498757</th>\n",
       "      <td>@DamienAidoo lol whateva! That's y ur hawks be...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707350</th>\n",
       "      <td>It's hot and I don't want to go work on the ol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936938</th>\n",
       "      <td>.@imymulla Brilliant work-around, thx for shar...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  sentiment\n",
       "1191014  @empian sure is, and they were on offer so tas...          4\n",
       "458592       ............      orlando magic making me sad          0\n",
       "1086868            @iAmCherAnn Really? Allison said that?           4\n",
       "387691   i want to go to america NOW! i dont want to wa...          0\n",
       "552737   Dont like going to sleep after being full off ...          0\n",
       "1521780  @kaypros Thanks. You are so right - great venu...          4\n",
       "1140025  Kobayashi beats Chestnut! http://tinyurl.com/n...          4\n",
       "1498757  @DamienAidoo lol whateva! That's y ur hawks be...          4\n",
       "707350   It's hot and I don't want to go work on the ol...          0\n",
       "936938   .@imymulla Brilliant work-around, thx for shar...          4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fuck this economy. I hate aig and their non lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jquery is my new best friend.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Loves twitter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how can you not love Obama? he makes jokes abo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...          4\n",
       "1  Reading my kindle2...  Love it... Lee childs i...          4\n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...          4\n",
       "3  @kenburbary You'll love your Kindle2. I've had...          4\n",
       "4  @mikefish  Fair enough. But i have the Kindle2...          4\n",
       "5  @richardebaker no. it is too big. I'm quite ha...          4\n",
       "6  Fuck this economy. I hate aig and their non lo...          0\n",
       "7                      Jquery is my new best friend.          4\n",
       "8                                      Loves twitter          4\n",
       "9  how can you not love Obama? he makes jokes abo...          4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rows: 800000\n",
      "Negative rows: 800000\n"
     ]
    }
   ],
   "source": [
    "print('Positive rows: {}'.format(train_data[ train_data['sentiment'] == 4]['sentiment'].size))\n",
    "print('Negative rows: {}'.format(train_data[ train_data['sentiment'] == 0]['sentiment'].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_cell_guid": "43632d2d-6160-12ce-48b0-e5eb1c207076"
   },
   "outputs": [],
   "source": [
    "# Only keep top 10000 words in the corpus.\n",
    "max_fatures = 10000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(train_data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(train_data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 116)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   15, 1310,  156],\n",
       "       [   0,    0,    0, ...,  341,   14,  110],\n",
       "       [   0,    0,    0, ..., 5629,  303,   17],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    6,    3,  493],\n",
       "       [   0,    0,    0, ...,  945,   36,   87],\n",
       "       [   0,    0,    0, ..., 2190,   46, 2379]], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_cell_guid": "b35748b8-2353-3db2-e571-5fd22bb93eb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.get_dummies(train_data['sentiment']).values\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33500, 116) (33500, 2)\n",
      "(16500, 116) (16500, 2)\n"
     ]
    }
   ],
   "source": [
    "size_limit = 500000\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X[:size_limit],Y[:size_limit], test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 116, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_12 (Spatia (None, 116, 200)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_19 (CuDNNLSTM)    (None, 116, 500)          1404000   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_20 (CuDNNLSTM)    (None, 500)               2004000   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 5,409,002\n",
      "Trainable params: 5,409,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 200\n",
    "lstm_out = 500\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(rate=0.5))\n",
    "model.add(CuDNNLSTM(lstm_out, return_sequences=True))\n",
    "model.add(CuDNNLSTM(lstm_out))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "_cell_guid": "d5e499ac-2eba-6ff7-8d9a-ff65eb04099b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      " - 116s - loss: 0.5320 - acc: 0.7321\n",
      "Epoch 2/7\n",
      " - 115s - loss: 0.4230 - acc: 0.8083\n",
      "Epoch 3/7\n",
      " - 115s - loss: 0.3616 - acc: 0.8391\n",
      "Epoch 4/7\n",
      " - 115s - loss: 0.3092 - acc: 0.8650\n",
      "Epoch 5/7\n",
      " - 115s - loss: 0.2602 - acc: 0.8887\n",
      "Epoch 6/7\n",
      " - 115s - loss: 0.2207 - acc: 0.9056\n",
      "Epoch 7/7\n",
      " - 115s - loss: 0.1839 - acc: 0.9215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe32c4996a0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4ebd7bc1-53c0-0e31-a0b0-b6d0a3017434"
   },
   "source": [
    "Extracting a validation set, and measuring score and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "_cell_guid": "a970f412-722f-6d6d-72c8-325d0901ccef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.77538238\n",
      "acc: 0.75387879\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.8f\" % (score))\n",
    "print(\"acc: %.8f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve:\n",
    "1. The model is suffering from overfitting. We should add more dropout layers and try other regularization methods.\n",
    "2. Systematically search for the optimal combination of hyperparameters"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 185,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
